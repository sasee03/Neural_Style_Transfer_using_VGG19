{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ac8Af3SFeA1s",
        "outputId": "3fa2e8bc-640c-48f3-97c3-94ed40a02994"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.114.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import tensorflow.keras.applications.vgg19 as vgg19\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "3cjUBj3Ha_q0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(image):\n",
        "    max_dim = 512\n",
        "    img = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "    long_dim = max(shape)\n",
        "    scale = max_dim / long_dim\n",
        "    new_shape = tf.cast(shape * scale, tf.int32)\n",
        "    img = tf.image.resize(img, new_shape)\n",
        "    img = img[tf.newaxis, :]\n",
        "    return img"
      ],
      "metadata": {
        "id": "06F4k0p9a_oE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_image(tensor):\n",
        "    tensor = tensor * 255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor) > 3:\n",
        "        tensor = tensor[0]\n",
        "    return PIL.Image.fromarray(tensor)\n",
        "\n",
        "def vgg_layers(layer_names):\n",
        "    vgg = vgg19.VGG19(include_top=False, weights='imagenet')\n",
        "    vgg.trainable = False\n",
        "    outputs = [vgg.get_layer(name).output for name in layer_names]\n",
        "    model = tf.keras.Model([vgg.input], outputs)\n",
        "    return model\n",
        "\n",
        "def gram_matrix(input_tensor):\n",
        "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "    input_shape = tf.shape(input_tensor)\n",
        "    num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n",
        "    return result / num_locations"
      ],
      "metadata": {
        "id": "ZXzKPuxOa_lE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StyleContentModel(tf.keras.models.Model):\n",
        "    def __init__(self, style_layers, content_layers):\n",
        "        super(StyleContentModel, self).__init__()\n",
        "        self.vgg = vgg_layers(style_layers + content_layers)\n",
        "        self.style_layers = style_layers\n",
        "        self.content_layers = content_layers\n",
        "        self.num_style_layers = len(style_layers)\n",
        "        self.vgg.trainable = False\n",
        "    def call(self, inputs):\n",
        "        inputs = inputs * 255.0\n",
        "        preprocessed_input = vgg19.preprocess_input(inputs)\n",
        "        outputs = self.vgg(preprocessed_input)\n",
        "        style_outputs, content_outputs = (outputs[:self.num_style_layers], outputs[self.num_style_layers:])\n",
        "        style_outputs = [gram_matrix(style_output) for style_output in style_outputs]\n",
        "        content_dict = {content_name: value for content_name, value in zip(self.content_layers, content_outputs)}\n",
        "        style_dict = {style_name: value for style_name, value in zip(self.style_layers, style_outputs)}\n",
        "        return {'content': content_dict, 'style': style_dict}"
      ],
      "metadata": {
        "id": "izNpBkv_a_iE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_0_1(image):\n",
        "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "def style_content_loss(outputs, style_targets, content_targets, style_weight, content_weight):\n",
        "    style_outputs = outputs['style']\n",
        "    content_outputs = outputs['content']\n",
        "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name] - style_targets[name]) ** 2) for name in style_outputs.keys()])\n",
        "    style_loss *= style_weight / len(style_outputs)\n",
        "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name] - content_targets[name]) ** 2) for name in content_outputs.keys()])\n",
        "    content_loss *= content_weight / len(content_outputs)\n",
        "    return style_loss + content_loss"
      ],
      "metadata": {
        "id": "poAKoa8Ga_fc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total_variation_loss(image):\n",
        "    x_deltas, y_deltas = high_pass_x_y(image)\n",
        "    return tf.reduce_sum(tf.abs(x_deltas)) + tf.reduce_sum(tf.abs(y_deltas))\n",
        "def high_pass_x_y(image):\n",
        "    x_var = image[:, :, 1:, :] - image[:, :, :-1, :]\n",
        "    y_var = image[:, 1:, :, :] - image[:, :-1, :, :]\n",
        "    return x_var, y_var"
      ],
      "metadata": {
        "id": "_owZ5rjOa_cb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function()\n",
        "def train_step(image, extractor, style_targets, content_targets, style_weight, content_weight, tv_weight, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        outputs = extractor(image)\n",
        "        loss = style_content_loss(outputs, style_targets, content_targets, style_weight, content_weight)\n",
        "        loss += tv_weight * total_variation_loss(image)\n",
        "    grad = tape.gradient(loss, image)\n",
        "    optimizer.apply_gradients([(grad, image)])\n",
        "    image.assign(clip_0_1(image))"
      ],
      "metadata": {
        "id": "PXMjkRGKa_Z0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_style_transfer(content_image, style_image, epochs=10, steps_per_epoch=100, style_weight=1e-2, content_weight=1e4, tv_weight=30):\n",
        "    content_image = load_img(content_image)\n",
        "    style_image = load_img(style_image)\n",
        "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "    content_layers = ['block5_conv2']\n",
        "    extractor = StyleContentModel(style_layers, content_layers)\n",
        "    style_targets = extractor(style_image)['style']\n",
        "    content_targets = extractor(content_image)['content']\n",
        "    image = tf.Variable(content_image)\n",
        "    opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "    for n in range(epochs):\n",
        "        for m in range(steps_per_epoch):\n",
        "            train_step(image, extractor, style_targets, content_targets, style_weight, content_weight, tv_weight, opt)\n",
        "    return tensor_to_image(image)"
      ],
      "metadata": {
        "id": "x2v8Q-qQa_QU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_style_transfer(content_img, style_img):\n",
        "    result_image = run_style_transfer(content_img, style_img, epochs=10, steps_per_epoch=50)\n",
        "    return result_image\n",
        "interface = gr.Interface(\n",
        "    fn=gradio_style_transfer,\n",
        "    inputs=[\n",
        "        gr.Image(label=\"Content Image\"),\n",
        "        gr.Image(label=\"Style Image\")\n",
        "    ],\n",
        "    outputs=gr.Image(label=\"Stylized Image\"),\n",
        "    title=\"Neural Style Transfer\"\n",
        ")\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "2DjSiKjjN3mw",
        "outputId": "8320d0ce-623d-46b2-862b-140a42a9d8e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://58d8741db2762fba6c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://58d8741db2762fba6c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}
